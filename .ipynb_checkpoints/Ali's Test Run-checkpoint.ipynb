{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"Atorvastatin\": \"\"\"Concurrent use of ATORVASTATIN and GRAPEFRUIT JUICE may result in increased bioavailability of atorvastatin resulting in an increased risk of myopathy or rhabdomyolysis\"\"\", \"Viagra\": [\"Concurrent use of SILDENAFIL and GRAPEFRUIT JUICE may result in increased sildenafil bioavailability and delayed sildenafil absorption.\", \"Concurrent use of SILDENAFIL and POMELO JUICE may result in reduced plasma concentrations and efficacy of sildenafil.\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What prescriptions do you currently take?Viagra\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-784a711f6108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What prescriptions do you currently take?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrugs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "takes = input(\"What prescriptions do you currently take?\")\n",
    "if takes in dictionary:\n",
    "    print(dictionary[drugs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocessing import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "Professionalism & Ethics\n",
    "Mr. Manley:\n",
    "\n",
    "I can understand and appreciate the difficulties associated with the convolution of my academic petitions and procedures.  I have been embedded within them attempting to register and matriculate since 2019.  \n",
    "\n",
    "I should respecify my intentions beyond what you indicate below.  I recognize the necessity for a standard protocol for all student services, whether related to enrollment following a medical leave or otherwise.  That is not the problem area—as I believe you know.  \n",
    "\n",
    "It is overly simplistic to point to an individual instruction set as lying within the purview of policy.  Our discussions have revolved around Dr. Waters and the guidance he has provided me.  I am not pointing to any specific procedural guidance overtly encumbering; instead, I am pointing to a nexus of misinformation that starts well before Dr. Waters and even Luis Ramirez.  \n",
    "\n",
    "Isolating our frame of focus on Dr. Waters precludes the recognition that Luis Ramirez, months before Dr. Waters contacted me, provided an entirely different set of instructions with precisely the same objective in mind.  \n",
    "\n",
    "\n",
    "While I believe it is true, the friction against my upward progress is most readily apparent when attempting to explain \n",
    "\n",
    "\n",
    "The difficulties with my ongoing academic process, and those that I have expressed to you and Mr. Blanton, are not in line with school policies.  \n",
    "\n",
    "Ali,\n",
    " \n",
    "Our office has tried to provide as much second-hand clarification about the petition process and your questions as we are able to within our capacity.  Keeping up with the significant volume of emails and information you have sent us on a daily basis has been challenging, and we have made every effort to try to glean anything we feel crosses over into our office.  As mentioned before, we are not a stakeholder in your academic program nor do we have oversight over the plan the University has set out for you to achieve your academic goals.  Your questions and concerns about the petition process and registration of courses need to be addressed through those offices that are able to guide you.\n",
    " \n",
    "This petition process and associated guidelines around the PDP program are not unique to you as a student.  We do not see the process as unduly burdensome nor punitive based on the information that we have reviewed. \n",
    " ",
    "If there are resources, such as the Disability Services and Program (DSP) or the Campus Support and Intervention (CSI), that you feel should be providing you with services, please do not hesitate to reach out to those offices.  Our office is not in a position to oversee or direct those resource offices as they operate independently and with subject matter expertise and policies outside of our scope. \n",
    " \n",
    "If you have ultimately exhausted all efforts to follow the petition plan and are unsuccessful in matriculating back to the University and feel that the University has violated policy or has not afforded you equal opportunity to re-enroll, you may file a complaint with our office at that time.  We will then review and consult with the appropriate University office who has purview over these type of concerns.\n",
    " \n",
    "We wish you well and are hopeful that you are able to fulfill your academic endeavors.\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_poem = preprocess_text(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = vectorizer.fit_transform([processed_poem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_term_frequencies = pd.DataFrame(term_frequencies.T.todense(), index=feature_names, columns=['Term Frequency'])\n",
    "    print(df_term_frequencies)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from term_frequency import term_frequencies, feature_names, df_term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit TfidfTransformer\n",
    "transformer = TfidfTransformer(norm=None)\n",
    "transformer.fit(term_frequencies)\n",
    "idf_values = transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Inverse Document Frequency\n",
      "abash                      2.252763\n",
      "across                     2.252763\n",
      "admire                     2.252763\n",
      "again                      2.252763\n",
      "agonize                    2.252763\n",
      "...                             ...\n",
      "word                       2.252763\n",
      "wreck                      2.252763\n",
      "yet                        2.252763\n",
      "you                        2.252763\n",
      "your                       2.252763\n",
      "\n",
      "[173 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# create pandas DataFrame with inverse document frequencies\n",
    "try:\n",
    "    df_idf = pd.DataFrame(idf_values, index = feature_names, columns=['Inverse Document Frequency'])\n",
    "    print(df_idf)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Poem 1  Poem 2  Poem 3  Poem 4  Poem 5  Poem 6\n",
      "abash         0       0       0       0       1       0\n",
      "across        0       0       0       1       0       0\n",
      "admire        0       0       1       0       0       0\n",
      "again         0       0       0       1       0       0\n",
      "agonize       1       0       0       0       0       0\n",
      "...         ...     ...     ...     ...     ...     ...\n",
      "word          0       0       0       0       1       0\n",
      "wreck         0       0       0       1       0       0\n",
      "yet           0       0       0       0       1       0\n",
      "you           0       0       3       0       0       0\n",
      "your          0       0       1       0       0       0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_term_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from poems import poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_poems = [preprocess_text(poem) for poem in poems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = vectorizer.fit_transform(processed_poems)\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
