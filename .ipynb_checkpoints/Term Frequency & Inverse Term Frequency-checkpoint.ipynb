{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bound-contract",
   "metadata": {},
   "source": [
    "# Part I: Term Frequency\n",
    "Term frequency calculated in Python using scikit-learn `CountVectorizer`:\n",
    "\n",
    "```python\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "term_frequencies = vectorizer.fit_transform([stanza])\n",
    "```\n",
    "- A `CountVectorizer` object is initialized\n",
    "- The `CountVectorizer` object is fit (trained) and transformed (applied) on the corpus of data, returning the term frequencies for each term-document pair\n",
    "\n",
    "```python\n",
    "import codecademylib3_seaborn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocessing import preprocess_text\n",
    "\n",
    "poem = '''\n",
    "Success is counted sweetest\n",
    "By those who ne'er succeed.\n",
    "To comprehend a nectar\n",
    "Requires sorest need.\n",
    "\n",
    "Not one of all the purple host\n",
    "Who took the flag to-day\n",
    "Can tell the definition,\n",
    "So clear, of victory,\n",
    "\n",
    "As he, defeated, dying,\n",
    "On whose forbidden ear\n",
    "The distant strains of triumph\n",
    "Break, agonized and clear!'''\n",
    "\n",
    "# define clear_count:\n",
    "clear_count = 2\n",
    "\n",
    "# preprocess text\n",
    "processed_poem = preprocess_text(poem)\n",
    "\n",
    "# initialize and fit CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "term_frequencies = vectorizer.fit_transform([processed_poem])\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# create pandas DataFrame with term frequencies\n",
    "try:\n",
    "  df_term_frequencies = pd.DataFrame(term_frequencies.T.todense(), index=feature_names, columns=['Term Frequency'])\n",
    "  print(df_term_frequencies)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-geology",
   "metadata": {},
   "source": [
    "# Part II: Inverse document frequency\n",
    "We can calculate the inverse document frequency for some term `t` across a corpus using the below equation. \n",
    "$$\n",
    "\\log \\left(\\frac{\\text { Total number of documents }}{\\text { Number of documents with term } t}\\right)\n",
    "$$\n",
    "Inverse document frequency can be calculated on a group of documents using scikit-learn’s TfidfTransformer:\n",
    "```python\n",
    "transformer = TfidfTransformer(norm=None)\n",
    "transformer.fit(term_frequencies)\n",
    "inverse_doc_frequency = transformer.idf_\n",
    "```\n",
    "- a `TfidfTransformer` object is initialized. Don’t worry about the norm=None keyword argument for now, we will dig into this in the next exercise\n",
    "- the `TfidfTransformer` is fit (trained) on a term-document matrix of term frequencies\n",
    "- the `.idf_` attribute of the `TfidfTransformer` stores the inverse document frequencies of the terms as a NumPy array\n",
    "\n",
    "```python\n",
    "import codecademylib3_seaborn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from term_frequency import term_frequencies, feature_names, df_term_frequencies\n",
    "\n",
    "# display term-document matrix of term frequencies\n",
    "print(df_term_frequencies)\n",
    "\n",
    "# initialize and fit TfidfTransformer\n",
    "transformer = TfidfTransformer(norm=None)\n",
    "transformer.fit(term_frequencies)\n",
    "idf_values = transformer.idf_\n",
    "\n",
    "# create pandas DataFrame with inverse document frequencies\n",
    "try:\n",
    "  df_idf = pd.DataFrame(idf_values, index = feature_names, columns=['Inverse Document Frequency'])\n",
    "  print(df_idf)\n",
    "except:\n",
    "  pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-experience",
   "metadata": {},
   "source": [
    "# Part III: Putting it together\n",
    "Putting It All Together: Tf-idf\n",
    "Now that we understand how term frequency and inverse document frequency are calculated, let’s put it all together to calculate tf-idf!\n",
    "\n",
    "Tf-idf scores are calculated on a term-document basis. That means there is a tf-idf score for each word, for each document. The tf-idf score for some term `t` in a document `d` in some `corpus` is calculated as follows:\n",
    "\n",
    "$$\n",
    "t f i d f(t, d)=t f(t, d) * i d f(t, \\text { corpus })\n",
    "$$\n",
    "\n",
    "- `tf(t,d)` is the term frequency of term `t` in document `d`\n",
    "- `idf(t,corpus)` is the inverse document frequency of a term `t` across `corpus`\n",
    "We can easily calculate the tf-idf values for each term-document pair in our corpus using scikit-learn’s `TfidfVectorizer`:\n",
    "\n",
    "```python\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf_vectorizer = vectorizer.fit_transform(corpus)\n",
    "```\n",
    "\n",
    "- a `TfidfVectorizer` object is initialized. The `norm=None` keyword argument prevents scikit-learn from modifying the multiplication of term frequency and inverse document frequency\n",
    "- the `TfidfVectorizer` object is fit and transformed on the corpus of data, returning the tf-idf scores for each term-document pair\n",
    "\n",
    "```python\n",
    "import codecademylib3_seaborn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from poems import poems\n",
    "from preprocessing import preprocess_text\n",
    "\n",
    "# preprocess documents\n",
    "processed_poems = [preprocess_text(poem) for poem in poems]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "\n",
    "\n",
    "\n",
    "# get vocabulary of terms\n",
    "tfidf_scores = vectorizer.fit_transform(processed_poems)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# get corpus index\n",
    "corpus_index = [f\"Poem {i+1}\" for i in range(len(poems))]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-bronze",
   "metadata": {},
   "source": [
    "# Converting Bag-of-Words to Tf-idf\n",
    "In addition to directly calculating the tf-idf scores for a set of terms across a corpus, you can also convert a bag-of-words model you have already created into tf-idf scores.\n",
    "\n",
    "Scikit-learn’s `TfidfTransformer` is up to the task of converting your bag-of-words model to tf-idf. You begin by initializing a `TfidfTransformer` object.\n",
    "\n",
    "```python\n",
    "tf_idf_transformer = TfidfTransformer(norm=False)\n",
    "```\n",
    "\n",
    "Given a bag-of-words matrix `count_matrix`, you can now multiply the term frequencies by their inverse document frequency to get the tf-idf scores as follows:\n",
    "\n",
    "```python\n",
    "tf_idf_scores = tfidf_transformer.fit_transform(count_matrix)\n",
    "```\n",
    "\n",
    "This is very similar to how we calculated inverse document frequency, except this time we are fitting and transforming the `TfidfTransformer` to the term frequencies/bag-of-words vectors rather than just fitting the `TfidfTransformer` to them.\n",
    "\n",
    "```python\n",
    "import codecademylib3_seaborn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from term_frequency import bow_matrix, feature_names, df_bag_of_words, corpus_index\n",
    "\n",
    "# display term-document matrix of term frequencies (bag-of-words)\n",
    "print(df_bag_of_words)\n",
    "\n",
    "# initialize and fit TfidfTransformer, transform bag-of-words matrix\n",
    "transformer = TfidfTransformer(norm=False)\n",
    "tfidf_scores = transformer.fit_transform(bow_matrix)\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index = feature_names, columns=corpus_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
